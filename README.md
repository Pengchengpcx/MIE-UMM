# Towards Generalized Multi-Image Editing for Unified Multimodal Models 

<div style="display: flex; justify-content: center; align-items: center;">
  <a href="https://arxiv.org/abs/2601.05572" style="margin: 0 2px;">
    <img src='https://img.shields.io/badge/arXiv-2411.10499-red?style=flat&logo=arXiv&logoColor=red' alt='arxiv'>
  </a>
</div>

**TL;DR**: We propose a scalable multi-image editing framework for UMMs that explicitly encodes image identities to improve visual consistency and disambiguate references in the multi-image setting. By introducing learnable latent separators and sinusoidal index encoding—along with a high-fidelity benchmark—our method achieves stronger semantic consistency, visual fidelity, and cross-image integration than prior baselines.

**Pengcheng Xu | Peng Tang | Donghao Luo | Xiaobin Hu | Weichu Cui | Qingdong He | Zhennan Chen | Jiangning Zhang | Charles Ling | Boyu Wang**

> Western University
> 
> Tencent


<div align='center'>
<img src="./assets/arch.png" class="interpolation-image" alt="arch." height="100%" width="100%" />
</div>

## Benchmark



## Setup



## Evaluation




